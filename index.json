
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"I’m a master student from School of Geodesy and Geomatics, Wuhan University. My research interest includes multi-sensor fusion, Global Navigation Satellite System (GNSS), indoor-outdoor seamless positioning, Simultaneous Localization and Mapping (SLAM), and sensor calibration. I am very fortunate to be advised by Prof. Xingxing Li of GREAT Lab from School of Geodesy and Geomatics, Wuhan University.\n","date":1697068800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1697068800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I’m a master student from School of Geodesy and Geomatics, Wuhan University. My research interest includes multi-sensor fusion, Global Navigation Satellite System (GNSS), indoor-outdoor seamless positioning, Simultaneous Localization and Mapping (SLAM), and sensor calibration.","tags":null,"title":"Zongzhou Wu","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://zzwu29.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Zongzhou Wu"],"categories":["research"],"content":"Project https://github.com/zzwu29/SuperPointCPP\n","date":1697068800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1697068800,"objectID":"af8e7e8839d3d2ba97e5897a1bdb1ee0","permalink":"https://zzwu29.github.io/post/superpointcpp/","publishdate":"2023-10-12T00:00:00Z","relpermalink":"/post/superpointcpp/","section":"post","summary":"Superpoint C++ function","tags":["computer vision","feature detector"],"title":"SuperPointCPP","type":"post"},{"authors":["Zongzhou Wu"],"categories":["research"],"content":"Introduction When I tried to solve a state estimation via visual-inertial odometry, I found that the some photos captured by camera were lost.\nOpen-source Project https://film-net.github.io/ https://github.com/google-research/frame-interpolation Paper https://arxiv.org/pdf/2202.04901\nScripts Download\nProblem significant linear motion turn a corner frame interval too long (\u0026gt;= 0.2s in autonomous driving) ","date":1696982400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696982400,"objectID":"2d4abfbb3ad7fec031fb12412732fca1","permalink":"https://zzwu29.github.io/post/frame-interpolation/","publishdate":"2023-10-11T00:00:00Z","relpermalink":"/post/frame-interpolation/","section":"post","summary":"interpolation of images and videos","tags":["computer vision"],"title":"Frame Interpolation","type":"post"},{"authors":["Zongzhou Wu"],"categories":["journey"],"content":"Changqing park Marshland Northwest lake Yellow Crane Tower Zhangbi lake park East lake ","date":1695168000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695168000,"objectID":"b2f4ae25c21ad66d31fa956dc56430af","permalink":"https://zzwu29.github.io/post/drone-shot-wuhan/","publishdate":"2023-09-20T00:00:00Z","relpermalink":"/post/drone-shot-wuhan/","section":"post","summary":"Wuhan","tags":["drone shot"],"title":"Drone Shot","type":"post"},{"authors":null,"categories":null,"content":" ","date":1694995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1694995200,"objectID":"93ef502defab0071010dd4352b060f8d","permalink":"https://zzwu29.github.io/project/superpointcpp/","publishdate":"2023-09-18T00:00:00Z","relpermalink":"/project/superpointcpp/","section":"project","summary":"An implement of SuperPoint feature detector in C++","tags":["Tool"],"title":"SuperPointCPP","type":"project"},{"authors":["Xingxing Li","Zongzhou Wu","Zhiheng Shen","Zhili Xu","Xin Li","Shengyu Li","Junjie Han"],"categories":null,"content":" ","date":1693958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1693958400,"objectID":"e2440e551f719d64fbb8fa3d1a240bf0","permalink":"https://zzwu29.github.io/publication/journal-article/jsen-1/","publishdate":"2023-10-16T00:00:00Z","relpermalink":"/publication/journal-article/jsen-1/","section":"publication","summary":"Seamless positioning is critical for mobile robots to achieve ubiquitous availability in all scenarios. The precise point positioning (PPP) technique provides a centimeter-level solution without a reference station and is often integrated with an inertial navigation system (INS) for outdoor navigation of unmanned ground vehicles (UGVs). However, in challenging environments such as indoors, the performance of PPP/INS systems is severely degraded, while ultrawideband (UWB) is widely used due to its high accuracy over short distances. This article proposes a tightly coupled (TC) PPP/INS/UWB integrated system, in which satellite-difference ionosphere-free (SD-IF) pseudorange and carrier-phase measurements from a single receiver, microelectromechanical system (MEMS) inertial measurements, and the UWB rangings are tightly fused to accomplish continuous and precise positioning throughout indoor and outdoor coverage. To mitigate the effects of nonline-of-sight (NLOS), multipath, and faulty signals, a two-step weighting approach is proposed to improve UWB positioning performance, including segmentation weighting based on the signal strength, and weight adjustment based on area identification. Besides, motion constraints are imposed on velocity, yaw, and height to suppress drifts during signal-harsh periods. Real-world experiment results show that the proposed system can achieve continuous positioning in the overall indoor and outdoor environments, with the mean absolute errors (MAEs) of (0.214, 0.186, and 0.243 m) and the root mean square errors (RMSEs) of (0.339, 0.291, and 0.414 m) in the east, north, and up directions. In transitional areas with severe signal interference and interruption, a 0.5 m positioning accuracy and smooth switching are still attainable.","tags":["Seamless positioning"],"title":"An indoor and outdoor seamless positioning system for low-cost UGV using PPP/INS/UWB tightly coupled integration","type":"publication"},{"authors":["Zongzhou Wu"],"categories":["research"],"content":"Title An indoor and outdoor seamless positioning system for low-cost UGV using PPP/INS/UWB tightly coupled integration\nPublished in: IEEE Sensors Journal\nAuthor Xingxing Li, Zongzhou Wu, Zhiheng Shen, Zhili Xu, Xin Li, Shengyu Li and Junjie Han\nAbstract Seamless positioning is critical for mobile robots to achieve ubiquitous availability in all scenarios. Precise point positioning (PPP) technique provides a centimeter-level solution without a reference station and is often integrated with an inertial navigation system (INS) for outdoor navigation of unmanned ground vehicles (UGVs). However, in challenging environments such as indoors, the performance of PPP/INS systems is severely degraded, while ultra-wideband (UWB) is widely used due to its high accuracy over short distances. This paper proposes a tightly coupled PPP/INS/UWB integrated system, in which satellite-difference ionosphere-free pseudorange and carrier-phase measurements from a single receiver, micro-electro-mechanical system (MEMS) inertial measurements, and the UWB rangings are tightly fused to accomplish continuous and precise positioning throughout indoor and outdoor coverage. To mitigate the effects of non-line-of-sight (NLOS), multipath and faulty signals, a two-step weighting approach is proposed to improve UWB positioning performance, including segmentation weighting based on the signal strength, and weight adjustment based on area identification. Besides, motion constraints are imposed on velocity, yaw, and height to suppress drifts during signal-harsh periods. Real-world experiment results show that the proposed system can achieve continuous positioning in the overall indoor and outdoor environments, with the MAEs of (0.214 m, 0.186 m, 0.243 m) and the RMSEs of (0.339 m, 0.291 m, 0.414 m) in the east, north, and up directions. In transitional areas with severe signal interference and interruption, a 0.5 m positioning accuracy and smooth switching are still attainable.\nKeyword Area identification, micro-electro-mechanical system, multisensor fusion, precise point positioning, seamless positioning, tightly coupled integration, ultra-wideband\nDOI 10.1109/JSEN.2023.3310480\nLink https://ieeexplore.ieee.org/document/10242329\n","date":1693180800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1693180800,"objectID":"14bb76616d48f8d19a17a7e55d9dda6f","permalink":"https://zzwu29.github.io/post/jsen-1/","publishdate":"2023-08-28T00:00:00Z","relpermalink":"/post/jsen-1/","section":"post","summary":"PPP/INS/UWB tightly coupled integration","tags":["seamless positioning","sensor fusion"],"title":"A work on indoor-outdoor positioning","type":"post"},{"authors":["Xingxing Li","Junjie Han","Xin Li","Jiaxin Huang","Zhiheng Shen","Zongzhou Wu"],"categories":null,"content":" ","date":1692835200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1692835200,"objectID":"a6034111b3420183db9a67f505b73d20","permalink":"https://zzwu29.github.io/publication/journal-article/gpss-1/","publishdate":"2023-08-24T00:00:00Z","relpermalink":"/publication/journal-article/gpss-1/","section":"publication","summary":" ","tags":["GNSS"],"title":"A grid-based ionospheric weighted method for PPP-RTK with diverse network scales and ionospheric activity levels","type":"publication"},{"authors":["Zongzhou Wu"],"categories":["journey"],"content":"Fairy hole ","date":1692316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1692316800,"objectID":"47eb3c75d6a878b0be548b69dc63a6d9","permalink":"https://zzwu29.github.io/post/drone-shot-shenzhen/","publishdate":"2023-08-18T00:00:00Z","relpermalink":"/post/drone-shot-shenzhen/","section":"post","summary":"Shenzhen","tags":["drone shot"],"title":"Drone Shot","type":"post"},{"authors":["Zongzhou Wu"],"categories":["journey"],"content":"Museum ","date":1689811200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689811200,"objectID":"e450d80e6d96681111b27583e475b65e","permalink":"https://zzwu29.github.io/post/drone-shot-zhuhai/","publishdate":"2023-07-20T00:00:00Z","relpermalink":"/post/drone-shot-zhuhai/","section":"post","summary":"Zhuhai","tags":["drone shot"],"title":"Drone Shot","type":"post"},{"authors":["Chenjun Long","Zongzhou Wu","Zhiheng Shen"],"categories":null,"content":" ","date":1689033600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689033600,"objectID":"2acf6414052b431b7eda167bb56d7e44","permalink":"https://zzwu29.github.io/publication/journal-article/pnt-2/","publishdate":"2023-07-11T00:00:00Z","relpermalink":"/publication/journal-article/pnt-2/","section":"publication","summary":" ","tags":["Seamless positioning"],"title":"Review of high-precision multi-sensor integrated positioning toward intelligent driving","type":"publication"},{"authors":["Zhili Xu","Zhuohao Yan","Xingxing Li","Zhiheng Shen","Yuxuan Zhou","Zongzhou Wu","Xin Li"],"categories":null,"content":" ","date":1683763200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1683763200,"objectID":"b13fb5cccd53032f454d8d4fd8b6c969","permalink":"https://zzwu29.github.io/publication/journal-article/pnt-1/","publishdate":"2023-05-11T00:00:00Z","relpermalink":"/publication/journal-article/pnt-1/","section":"publication","summary":" ","tags":["autonomous driving"],"title":"Review of high-precision multi-sensor integrated positioning toward intelligent driving","type":"publication"},{"authors":null,"categories":null,"content":" ","date":1683504000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1683504000,"objectID":"3b6af753a25a9000e62c4a0f6af2fe8e","permalink":"https://zzwu29.github.io/project/viral_eval/","publishdate":"2023-05-08T00:00:00Z","relpermalink":"/project/viral_eval/","section":"project","summary":"Scripts to quickly calculate absolute/relative pose estimation error","tags":["Tool"],"title":"viral_eval","type":"project"},{"authors":["Zongzhou Wu"],"categories":["research"],"content":"Useful links https://matplotlib.org/stable/gallery/style_sheets/style_sheets_reference.html\nhttps://antv.antgroup.com/specification/language/palette\nhttp://www.cookbook-r.com/Graphs/Colors_(ggplot2)/\nhttps://matplotlib.org/stable/users/explain/colors/colormaps.html\nhttps://ggplot2.tidyverse.org/reference/#scales\nhttp://colorbrewer2.org/\nhttps://colorspace.r-forge.r-project.org/index.html\nhttps://github.com/garrettj403/SciencePlots\nhttps://github.com/mtennekes/cols4all\nhttps://github.com/coatless-rpkg/cetcolor\nhttps://materialui.co/\nhttp://brandcolors.net/\nhttps://moviesincolor.com/films\nhttps://personal.sron.nl/~pault/#sec:qualitative\nhttps://coolors.co/palettes/palettes\nhttps://www.webdesignrankings.com/resources/lolcolors/\nhttps://www.schemecolor.com/\nPalette example This browser does not support PDFs. Please download the PDF to view it: Download PDF.\n","date":1665273600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665273600,"objectID":"3c3a23b4164d6c1c28fb1ff205b413ee","permalink":"https://zzwu29.github.io/post/color-palettes/","publishdate":"2022-10-09T00:00:00Z","relpermalink":"/post/color-palettes/","section":"post","summary":"Color Palette Overview","tags":["color","palette","tool"],"title":"Palette","type":"post"},{"authors":null,"categories":null,"content":" ","date":1651017600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651017600,"objectID":"4bed5d093885bec217ce3e10d35cb520","permalink":"https://zzwu29.github.io/project/comparenavplot/","publishdate":"2022-04-27T00:00:00Z","relpermalink":"/project/comparenavplot/","section":"project","summary":"PySide2 UI for plotting IMU outputs, GNSS or GNSS/INS positioning results","tags":["Tool"],"title":"compareNavPlot","type":"project"},{"authors":["Zongzhou Wu"],"categories":["research"],"content":" Dataset Institution Year GNSS (Raw) IMU Camera LiDAR UWB Ground Truth Platform HKU MARS HKU 2023 √ (√) √ √ √ √ UAV STAR-loc UofT 2023 √ √ √ √ UAV S3E SYSU 2023 √ (×) √ √ √ √ 3×UGV GRACO SYSU 2023 √ (×) √ √ √ √ UAV/UGV Hilti Hilti 2023 √ √ √ √ Hand/UGV GVINS HKUST 2022 √ (√) √ √ √ Hand/Car VIRAL NTU 2022 √ √ √ √ √ UAV SJTU_GVI SJTU 2022 √ (√) √ √ √ Car UrbanNav PolyU 2022 √ (√) √ √ √ √ Car FusionPortable HKUST 2022 √ (×) √ √ √ √ Hand Marine Perception MIT 2022 √(×) √ √ √ √ Canoe Hilti Hilti 2022 √ √ √ √ Hand Insane University of Klagenfurt 2022 √(×) √ √ √ √ UAV Visual-Inertial-LiDAR Leibniz Universität Hannover 2022 √ √ √ Car VECtor ShanghaiTech University 2022 √ √ √ √ Hand M2DGR SJTU 2021 √ (√) √ √ √ √ UGV GroundRobot CAS 2021 √ (×) √ √ √ √ UGV Hilti Hilti 2021 √ √ √ √ Hand UTBM UTBM 2020 √ (×) √ √ √ √ Car UrbanLoco PolyU 2020 √ (√) √ √ √ √ Car TEX-CUP University of Texas Austin 2020 √(√) √ √ √ Car Kaist Urban KAIST 2019 √ (×) √ √ √ √ Car TUM VI TUM 2019 √ √ √ UGV FPV ETH 2019 √ √ √ UAV Canoe University of Illinois Board of Trustees 2018 √ √ √ Canoe MVSEC University of Pennsylvania 2018 √ √ √ √ Car/Motorbike/UAV/Hand Zurich MAV ETH 2017 √ (×) √ √ √ UAV Ford Ford 2017 √ (×) √ √ √ √ Car KITTI KIT 2016 √ (×) √ √ √ √ Car Robotcar Oxford 2016 √ (×) √ √ √ √ Car EuRoC ETH 2016 √ √ UAV Maplab ETH 2016 √ √ Hand ","date":1647302400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647302400,"objectID":"b75db12682b362f7f50101da48d6ef80","permalink":"https://zzwu29.github.io/post/slam-datasets/","publishdate":"2022-03-15T00:00:00Z","relpermalink":"/post/slam-datasets/","section":"post","summary":"SLAM dataset with different sensor suite","tags":["dataset","SLAM"],"title":"SLAM Dataset Overview","type":"post"},{"authors":["Zongzhou Wu"],"categories":["research"],"content":"Introduction Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.\nSeaborn website: https://seaborn.pydata.org/\nSeaborn Github: https://github.com/mwaskom/seaborn\nDependencies Seaborn supports Python 3.8+.\nInstallation requires numpy, pandas, and matplotlib. Some advanced statistical functionality requires scipy and/or statsmodels.\nInstallation pip install seaborn Object Interface In version 0.12, Seaborn introduced object namespace and interface, which are based on the Grammar of Graphics similiar to ggplot2 package in R. In the past, the best python package was plotnine that was absolutely consistent with ggplot2.\nExample Basic Plot import seaborn import seaborn.objects as so tips=seaborn.load_dataset(\u0026#34;tips\u0026#34;) ( so.Plot(tips, y=\u0026#34;day\u0026#34;, color=\u0026#34;sex\u0026#34;) .add(so.Bar(), so.Hist(), so.Dodge()) .show() ) Then figure will be like this\nIf you want to save the figure, just run\nimport seaborn as sns import seaborn.objects as so tips=sns.load_dataset(\u0026#34;tips\u0026#34;) ( so.Plot(tips, y=\u0026#34;day\u0026#34;, color=\u0026#34;sex\u0026#34;) .add(so.Bar(), so.Hist(), so.Dodge()) .save(\u0026#34;fig.pdf\u0026#34;,bbox_inches=\u0026#34;tight\u0026#34;) ## save ) bbox_inches=“tight” is necessary for saving legend like R.\nFacet import seaborn as sns import seaborn.objects as so penguins=sns.load_dataset(\u0026#34;penguins\u0026#34;) ( so.Plot(penguins, \u0026#34;bill_length_mm\u0026#34;, \u0026#34;bill_depth_mm\u0026#34;) .add(so.Dots()) .facet(\u0026#34;species\u0026#34;, \u0026#34;sex\u0026#34;) .show() ) Theme and Palette import seaborn as sns import seaborn.objects as so import matplotlib.pyplot as plt sns.set_theme(style=\u0026#34;white\u0026#34;, palette=\u0026#34;deep6\u0026#34;, font=\u0026#34;Times New Roman\u0026#34;, font_scale=1.5) ## settings tips=sns.load_dataset(\u0026#34;tips\u0026#34;) ( so.Plot(tips, \u0026#34;total_bill\u0026#34;, \u0026#34;tip\u0026#34;, color=\u0026#34;day\u0026#34;) .facet(col=\u0026#34;day\u0026#34;) .add(so.Dot(color=\u0026#34;#aabc\u0026#34;), col=None, color=None) .add(so.Dot()) .theme(plt.rcParams) ## important .show() ) Reference https://seaborn.pydata.org/api.html#objects-api\nhttps://seaborn.pydata.org/tutorial/objects_interface.html\n","date":1635379200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635379200,"objectID":"d5f91b5c4d79694895263e92406cb54d","permalink":"https://zzwu29.github.io/post/seaborn-objects/","publishdate":"2021-10-28T00:00:00Z","relpermalink":"/post/seaborn-objects/","section":"post","summary":"a advanced graphic grammar","tags":["tool"],"title":"Seaborn Objects","type":"post"},{"authors":["Zongzhou Wu"],"categories":["linux"],"content":"How to install nvidia driver on ubuntu 20.04 ? https://blog.csdn.net/qq_42887760/article/details/126903100?spm=1001.2014.3001.5506 https://blog.csdn.net/qq_38043069/article/details/128400761?spm=1001.2014.3001.5506 https://blog.csdn.net/wf19930209/article/details/81877822?spm=1001.2014.3001.5506\nLegion Y9000P bios: F2\nSetting discrete graphics\ntty: Ctrl + Alt + F(3/4/5……)\n","date":1620259200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620259200,"objectID":"16bda3d69041c122754556a4766def49","permalink":"https://zzwu29.github.io/post/nvidia-driver/","publishdate":"2021-05-06T00:00:00Z","relpermalink":"/post/nvidia-driver/","section":"post","summary":"How to install nvidia driver on ubuntu 20.04","tags":["tool","driver"],"title":"Ubuntu Nvidia Driver","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://zzwu29.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"}]